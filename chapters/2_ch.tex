\chapter{Unity Engine}
\label{chap:refs}
Unity is a cross-platform development environment widely used for building interactive applications, particularly video games. Its support for the C\# programming language, combined with extensive official documentation and a wealth of community-created tutorials, makes it highly accessible to developers of various experience levels. Our framework will be implemented in version Unity 2022.3.61f1. 

This chapter introduces essential Unity development concepts that form the foundation for the rest of the thesis. While experienced Unity users may already be familiar with this material, others can refresh their memory on basic concepts. For those who want to learn more, they are encouraged to study the Unity manual \cite{Unity-manual} for more in-depth information. 

\section{Scenes}
Unity organizes game content into units called \textit{scenes}, which commonly represent individual levels, menus, or other distinct game states. Developers can freely switch between these scenes, each serving as a workspace in which the game environment is built by placing and configuring various elements, referred to as \textit{GameObjects}. 

\section{GameObjects}
In Unity, all entities present within a scene are instances of the class \verb|GameObject|. This includes a wide range of elements such as characters, environmental props, cameras, lighting, and visual effects. A \verb|GameObject| serves as a fundamental container that represents an object in the scene. However, by itself, it does not possess any visual appearance or behavior.

\subsection{Parenting}
\verb|GameObjects| can be organized hierarchically by assigning one \verb|GameObject| as the parent of another. This parent-child relationship enables the construction of complex object groupings, where transformations applied to the parent automatically propagate to its children. Specifically, when a parent \verb|GameObject| is moved, rotated, or scaled, all child \verb|GameObjects| adjust accordingly to maintain their relative position, orientation, and size within the local coordinate space. This hierarchical structure is essential for building composite objects, such as characters with equipment, or UI elements grouped under a shared layout. 

\subsection{Components}
To define the appearance and functionality of a \verb|GameObject|, developers attach various \verb|Components| to it. Each \verb|Component| is responsible for a specific aspect of the \verb|GameObject|’s behavior, for example, rendering a sprite, detecting collisions, handling audio playback, or processing input. Through the combination of different Components, developers can create complex interactive objects from simple modular parts. This component-based system is a core aspect of Unity’s architecture and promotes a highly modular and reusable approach to game development. 

\section{Scripting}
Unity enables developers to define custom behaviors by writing scripts in C\#, the engine’s officially supported programming language. They are fundamental to gameplay logic and interactivity, as they allow developers to go beyond what is possible with Unity’s built-in \verb|Components|.

To function as a \verb|Component|, a script must define a class that inherits from \verb|MonoBehaviour|, a base class provided by Unity. Once a script is added, Unity automatically instantiates it for each G\verb|ameObject| it is attached to, treating it like any other \verb|Component| in the system.

Unity follows an event-driven execution model. Instead of exposing a main loop to the developer, the engine invokes certain predefined methods (\textit{event functions}) at specific points during runtime. These functions are identified by name, and Unity calls them automatically based on the object’s lifecycle stage. Common event functions include \verb|Awake()|, which is executed once when the script instance is loaded, \verb|Start()| which is called also once, just before the \verb|GameObject| becomes active, and \verb|Update()|, a method that Unity calls every frame. It is worth noting that Unity does not guarantee the order in which these event functions are executed across different \verb|GameObjects|. While the sequence (\verb|Awake()|, then \verb|Start()|, then \verb|Update()|, etc.) is maintained per object, their inter-object order is undefined. This non-determinism can introduce bugs if dependencies between objects are not properly accounted for.

\subsection{Editor}
A distinct category of scripts in Unity are \textit{Editor} scripts, which enable developers to customize and extend the Unity Editor itself. These scripts are not intended for gameplay, but rather to enhance the development workflow by modifying the editor’s interface and behavior. Common use cases include creating custom inspectors for specific components, adding new menu options, or developing entirely new editor windows. Editor scripts execute exclusively within the Unity Editor environment and do not run during gameplay. They typically rely on Unity-specific classes such as \verb|Editor| and \verb|EditorWindow|. To associate a custom editor with a specific script, the attribute \verb|[CustomEditor(typeof(...))]| is applied. This allows the developer to redefine how the script is displayed in Inspector when attached to a \verb|GameObject| as a \verb|Component|.


 \section{ScriptableObject}
In Unity, \verb|ScriptableObject| serves as a specialized data container designed for storing and sharing data across different parts of a project without relying on scene or object instantiation. Unlike \verb|MonoBehaviour|, which must be attached to a \verb|GameObject|, \verb|ScriptableObject| instances exist independently and are saved directly as assets within the project folder.

One of the key advantages of \verb|ScriptableObject| is its efficiency in memory management. When data is stored directly within prefabs using \verb|MonoBehaviour| scripts, every instantiation of the prefab creates a separate copy of that data. This can lead to unnecessary memory consumption, especially when the data is static or shared across many objects. By contrast, a \verb|ScriptableObject| stores this information in a centralized asset. All prefabs or components can then access the same reference, ensuring only a single instance of the data exists in memory. This architecture is particularly well-suited for handling immutable or rarely changing information, such as configuration settings, character stats, or environment parameters.

\section{User Interface}
Unity provides a comprehensive system for building user interfaces (UIs), including in-game menus, overlays, and interactive HUD elements. The UI is constructed using standard \verb|GameObjects|, each equipped with specialized Components designed for interface functionality. Unlike traditional \verb|GameObjects| that rely on the standard \verb|Transform| Component, UI elements use a \verb|RectTransform|, which offers additional features.

At the core of every Unity UI system is the \verb|Canvas|, a dedicated \verb|GameObject| that acts as the rendering surface for all UI elements. Any UI element must be a descendant of a \verb|Canvas| in order to be displayed correctly. Unity offers different render modes for the \verb|Canvas|, including screen-space and world-space rendering, depending on the desired user experience.

Unity includes a variety of built-in UI elements, both static and interactive. Common static components include \verb|Text| and \verb|Image|, which display labels and visual content, respectively. For interactivity, Unity provides standard controls such as \verb|Button|. UI elements can be positioned, scaled, and anchored relative to their parent objects or to other UI elements. These layout adjustments are typically made within the Unity Editor using visual tools and layout groups. User input is handled through Unity’s \verb|EventSystem|, which manages the dispatching of interaction events to the appropriate UI components.
